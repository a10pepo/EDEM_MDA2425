{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjNNHAuA8E9b"
      },
      "source": [
        "# Pipelines: Metaflow model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdbShWAs8E9c"
      },
      "source": [
        "##  Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDD_E3Ff8E9c",
        "outputId": "82f389a3-10a8-4d34-9ac0-3a6c3b9b7e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting metaflow==2.13.9 (from -r requirements.txt (line 1))\n",
            "  Downloading metaflow-2.13.9-py2.py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting pandas==2.2.3 (from -r requirements.txt (line 2))\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.6.1)\n",
            "Collecting optuna==4.2.0 (from -r requirements.txt (line 5))\n",
            "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from metaflow==2.13.9->-r requirements.txt (line 1)) (2.32.3)\n",
            "Collecting boto3 (from metaflow==2.13.9->-r requirements.txt (line 1))\n",
            "  Downloading boto3-1.37.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1->-r requirements.txt (line 4)) (3.5.0)\n",
            "Collecting alembic>=1.5.0 (from optuna==4.2.0->-r requirements.txt (line 5))\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna==4.2.0->-r requirements.txt (line 5))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna==4.2.0->-r requirements.txt (line 5))\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna==4.2.0->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna==4.2.0->-r requirements.txt (line 5)) (3.1.1)\n",
            "Collecting botocore<1.38.0,>=1.37.9 (from boto3->metaflow==2.13.9->-r requirements.txt (line 1))\n",
            "  Downloading botocore-1.37.9-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->metaflow==2.13.9->-r requirements.txt (line 1))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->metaflow==2.13.9->-r requirements.txt (line 1))\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna==4.2.0->-r requirements.txt (line 5)) (3.0.2)\n",
            "Downloading metaflow-2.13.9-py2.py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.37.9-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading botocore-1.37.9-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, jmespath, colorlog, pandas, botocore, alembic, s3transfer, optuna, boto3, metaflow\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.9 alembic-1.15.1 boto3-1.37.9 botocore-1.37.9 colorlog-6.9.0 jmespath-1.0.1 metaflow-2.13.9 optuna-4.2.0 pandas-2.2.3 s3transfer-0.11.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMPEtztv8E9d"
      },
      "source": [
        "## Set username"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xr2xsusC8E9d"
      },
      "outputs": [],
      "source": [
        "# Set username for workflows\n",
        "import os\n",
        "os.environ[\"USERNAME\"] = \"eduardo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btRVWwCK8E9d",
        "outputId": "20a23e77-8314-40d2-b6be-c833438025ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing metaflow_trainingflow.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile metaflow_trainingflow.py\n",
        "from metaflow import FlowSpec, Parameter, step\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "class TrainingFlow(FlowSpec):\n",
        "    # Define the parameters for the flow\n",
        "    max_depth = Parameter('max_depth', default=2, help='Max depth of the random forest classifier')\n",
        "    n_estimators = Parameter('n_estimators', default=100, help='Number of estimators for the random forest classifier')\n",
        "    random_state = Parameter('random_state', default=0, help='Random state for the random forest classifier')\n",
        "\n",
        "    @step\n",
        "    def start(self):\n",
        "        # Start the flow\n",
        "        self.next(self.ingest_data)\n",
        "\n",
        "    @step\n",
        "    def ingest_data(self):\n",
        "        from sklearn.datasets import load_iris\n",
        "\n",
        "        # Load the iris dataset\n",
        "        iris = load_iris()\n",
        "\n",
        "        #pylint: disable=no-member\n",
        "        self.X = iris.data\n",
        "        self.y = iris.target\n",
        "        #pylint: enable=no-member\n",
        "\n",
        "        self.next(self.split_data)\n",
        "\n",
        "    @step\n",
        "    def split_data(self):\n",
        "        #Split the data into train and test\n",
        "        # TODO: WRITE YOUR CODE HERE\n",
        "        self.X_train, self.X_test, self.y_train,self. y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42, stratify=self.y)\n",
        "\n",
        "        self.next(self.train)\n",
        "    @step\n",
        "\n",
        "    def train(self):\n",
        "        # Definir el modelo usando los parámetros de la clase TrainingFlow\n",
        "        self.model = RandomForestClassifier(\n",
        "            n_estimators=self.n_estimators,\n",
        "            max_depth=self.max_depth,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "\n",
        "        # Entrenar el modelo con los datos de entrenamiento\n",
        "        self.model.fit(self.X_train, self.y_train)\n",
        "\n",
        "        self.next(self.show_metrics)\n",
        "    @step\n",
        "    def show_metrics(self):\n",
        "        # Print some metrics\n",
        "        # TODO: WRITE YOUR CODE HERE\n",
        "        # Hacer predicciones en el conjunto de prueba\n",
        "        y_pred = self.model.predict(self.X_test)\n",
        "\n",
        "        # Calcular métricas\n",
        "        accuracy = accuracy_score(self.y_test, y_pred)\n",
        "        precision = precision_score(self.y_test, y_pred, average='macro')  # Cambia a 'weighted' si hay desbalance\n",
        "        recall = recall_score(self.y_test, y_pred, average='macro')\n",
        "        f1 = f1_score(self.y_test, y_pred, average='macro')\n",
        "        self.next(self.register_model)\n",
        "    @step\n",
        "    def register_model(self):\n",
        "        # Save the model in a pickle file in local storage\n",
        "        # TODO: WRITE YOUR CODE HERE\n",
        "        # Definir el nombre del archivo\n",
        "        model_filename = \"trained_model.pkl\"\n",
        "\n",
        "        # Guardar el modelo en un archivo pickle\n",
        "        with open(model_filename, \"wb\") as file:\n",
        "            pickle.dump(self.model, file)\n",
        "        self.next(self.end)\n",
        "    @step\n",
        "    def end(self):\n",
        "        pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    TrainingFlow()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEjeSHbb8E9d",
        "outputId": "fb8a6266-e9ab-4368-a308-2b4cb3a90670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[35m\u001b[1mMetaflow 2.13.9\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTrainingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:eduardo\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
            "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[32m\u001b[22m    Pylint not found, so extra checks are disabled.\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:21.666 \u001b[0m\u001b[1mWorkflow starting (run-id 1741609401665815):\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:21.674 \u001b[0m\u001b[32m[1741609401665815/start/1 (pid 5124)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:23.618 \u001b[0m\u001b[32m[1741609401665815/start/1 (pid 5124)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:23.623 \u001b[0m\u001b[32m[1741609401665815/ingest_data/2 (pid 5139)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:25.553 \u001b[0m\u001b[32m[1741609401665815/ingest_data/2 (pid 5139)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:25.558 \u001b[0m\u001b[32m[1741609401665815/split_data/3 (pid 5154)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:27.419 \u001b[0m\u001b[32m[1741609401665815/split_data/3 (pid 5154)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:27.424 \u001b[0m\u001b[32m[1741609401665815/train/4 (pid 5165)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:29.890 \u001b[0m\u001b[32m[1741609401665815/train/4 (pid 5165)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:29.895 \u001b[0m\u001b[32m[1741609401665815/show_metrics/5 (pid 5184)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:31.604 \u001b[0m\u001b[32m[1741609401665815/show_metrics/5 (pid 5184)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:31.608 \u001b[0m\u001b[32m[1741609401665815/register_model/6 (pid 5199)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:33.422 \u001b[0m\u001b[32m[1741609401665815/register_model/6 (pid 5199)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:33.426 \u001b[0m\u001b[32m[1741609401665815/end/7 (pid 5210)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:35.056 \u001b[0m\u001b[32m[1741609401665815/end/7 (pid 5210)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-03-10 12:23:35.057 \u001b[0m\u001b[1mDone!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python metaflow_trainingflow.py run --max_depth 2 --n_estimators 100 --random_state 0"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "productionalization",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "5ed29f95de7cc8ac0f18a32ccae5fbddd3dba9010e060d505f2ebe31fc64f080"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}