{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detección de objetos en imágenes con CNNs: Conteo de canastas de baloncesto 🏀 \n",
        "\n",
        "El objetivo principal de este proyecto es desarrollar un sistema de visión por computadora capaz de detectar el balón y el aro de baloncesto en un video, utilizando una red neuronal convolucional basada en la arquitectura YOLOv8. A partir de estas detecciones, el sistema implementa una lógica para contar automáticamente la cantidad de canastas realizadas durante el transcurso del video. Esta aplicación puede ser útil en contextos deportivos para análisis automático de jugadas o recopilación de estadísticas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset description, download and exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Nombre del conjunto de datos**: Basketball Detection (Versión 1)\n",
        "- **Fuente**: Roboflow Universe  \n",
        "  - **URL**: [https://universe.roboflow.com/basketball-6vyfz/basketball-detection-srfkd](https://universe.roboflow.com/basketball-6vyfz/basketball-detection-srfkd)\n",
        "  - **Licencia**: CC BY 4.0\n",
        "\n",
        "- **Contenido**: El conjunto de datos contiene imágenes de partidos de baloncesto anotadas con *bounding boxes* para distintos objetos clave en el juego.\n",
        "\n",
        "- **Clases de objetos**:\n",
        "  - `0`: Ball  \n",
        "  - `1`: Hoop with ball \n",
        "  - `2`: Player  \n",
        "  - `3`: Hoop  \n",
        "  - `4`: Player shooting  \n",
        "\n",
        "- **Formato de anotación**: YOLOv5/YOLOv8. Cada archivo `.txt` contiene una línea por objeto detectado con el siguiente formato:\n",
        "`<class_id> <x_center> <y_center> <width> <height>`.\n",
        "\n",
        "- **Distribución del dataset**:\n",
        "  - **Entrenamiento**: 9,599 imágenes (88%)\n",
        "  - **Validación**: 873 imágenes (8%)\n",
        "  - **Pruebas**: 436 imágenes (4%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data preparation and augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se aplicaron augmentations automáticas provistas por YOLOv8, incluyendo:\n",
        "- Escalado aleatorio\n",
        "- Desenfoque (blur)\n",
        "- CLAHE (mejora de contraste)\n",
        "- Transformación a escala de grises\n",
        "\n",
        "Esto ayudó a mejorar la robustez del modelo y evitar el sobreajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se seleccionó el modelo `yolov8l.pt` (versión large de YOLOv8) como punto de partida por su buen balance entre velocidad y precisión. El modelo fue ajustado para detectar las 5 clases del dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo fue entrenado durante **10 épocas** con imágenes de tamaño **640x640**. Se utilizó el optimizador **AdamW**, con validación automática después de cada época. El modelo mostró mejoras constantes en precisión y recall.\n",
        "\n",
        "- **Código de entrenamiento utilizado**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uW0EQREsH-8"
      },
      "source": [
        "Instalar la librería ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from google.colab import drive, files\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67GI0UP1s0Dk"
      },
      "source": [
        "Montar Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW1QhV5QsUCb",
        "outputId": "ea097fb4-94a7-4060-a6a8-2896460e2362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qELu7T2Zs49z"
      },
      "source": [
        "Cargar modelo YOLOv8l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2QEULwJsWpU"
      },
      "outputs": [],
      "source": [
        "# Cargar el modelo\n",
        "def load_model(model_path=\"yolov8l.pt\"):\n",
        "    model = YOLO(model_path)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUuqqexCs-AT"
      },
      "source": [
        "Entrenar el modelo con el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_IisodwtBPj"
      },
      "outputs": [],
      "source": [
        "# Función para reentrenar el modelo y guardarlo\n",
        "def retrain_model(model, train_data, epochs=10, batch=16, save_path=\"yolov8_custom.pt\"):\n",
        "    # Entrenar el modelo con los datos proporcionados\n",
        "    model.train(data=train_data, epochs=epochs, batch=batch)\n",
        "\n",
        "    # Guardar el modelo reentrenado\n",
        "    model.save(save_path)\n",
        "    print(f\"Modelo guardado en {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_zvAxBitIrs"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIc_WcLUsZ3j",
        "outputId": "4942db48-2eb7-4e9a-cca8-cfa79322e36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 83.7M/83.7M [00:00<00:00, 104MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.99 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=/content/drive/MyDrive/basketball/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 21.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5586655  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,633,695 parameters, 43,633,679 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 96.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/basketball/train/labels.cache... 9597 images, 0 backgrounds, 2 corrupt: 100%|██████████| 9599/9599 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/basketball/train/images/119_jpg.rf.9488c2eb7899362d87cd014c5dc8ca8a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/basketball/train/images/119_jpg.rf.974639efdbc3b7e45ad151fb110b98e9.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/basketball/train/images/119_jpg.rf.ef4dbb83db1d69dc7dc7f249865f94c4.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/basketball/train/images/185_jpg.rf.36369d29da945e0cbb2e7f2253c06a9b.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/basketball/train/images/185_jpg.rf.f653197f23d5cc7eda4e07982d00369f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/basketball/train/images/185_jpg.rf.f7b2bca1e505d60739115fbcfa68a14d.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/basketball/train/images/basketball_484_jpg.rf.eba3fa6a05657d4bf8074cf0d8c8486f.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/basketball/train/images/basketball_484_jpg.rf.eba3fa6a05657d4bf8074cf0d8c8486f.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/basketball/train/images/basketball_4_jpg.rf.a8336a8ab5242dfcf3cf4708fd8417f4.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/basketball/train/images/basketball_4_jpg.rf.a8336a8ab5242dfcf3cf4708fd8417f4.jpg'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/basketball/valid/labels.cache... 873 images, 0 backgrounds, 0 corrupt: 100%|██████████| 873/873 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/10      9.59G      1.426      1.541        1.5         45        640: 100%|██████████| 600/600 [38:12<00:00,  3.82s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:18<00:00,  1.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.633       0.43      0.519      0.289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/10      11.1G      1.523      1.486      1.594         48        640: 100%|██████████| 600/600 [07:42<00:00,  1.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:17<00:00,  1.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.635      0.479      0.555      0.317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/10      11.1G      1.433      1.337      1.522         48        640: 100%|██████████| 600/600 [07:38<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:18<00:00,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.688      0.541      0.605      0.354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/10      11.1G      1.359      1.183      1.461         39        640: 100%|██████████| 600/600 [07:37<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:17<00:00,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.766      0.662      0.746      0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/10      11.1G       1.28      1.061      1.411         49        640: 100%|██████████| 600/600 [07:36<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:17<00:00,  1.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.803      0.705      0.779      0.498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/10      11.1G      1.217     0.9549      1.366         53        640: 100%|██████████| 600/600 [07:36<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:17<00:00,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.792      0.733      0.809      0.537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/10      11.1G      1.161     0.8839      1.329         58        640: 100%|██████████| 600/600 [07:37<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:18<00:00,  1.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.815       0.77      0.841       0.57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/10      11.2G      1.113     0.8004      1.288         60        640: 100%|██████████| 600/600 [07:36<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:18<00:00,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.827        0.8      0.864      0.598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/10      11.2G      1.069     0.7405       1.26         38        640: 100%|██████████| 600/600 [07:37<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:17<00:00,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.865      0.819      0.889      0.626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/10      11.2G      1.021      0.682      1.226         34        640: 100%|██████████| 600/600 [07:37<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:17<00:00,  1.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.863       0.84      0.902      0.649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "10 epochs completed in 1.859 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.99 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 112 layers, 43,610,463 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:20<00:00,  1.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.865       0.84      0.902      0.649\n",
            "                     0        751        876      0.897      0.732      0.845      0.585\n",
            "                     1         78         78      0.837      0.858       0.91        0.7\n",
            "                     2        549       1690      0.878      0.875      0.923      0.637\n",
            "                     3        573        600      0.966      0.914      0.965      0.732\n",
            "                     4        164        164      0.745      0.823      0.865      0.593\n",
            "Speed: 0.3ms preprocess, 15.5ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Modelo guardado en /content/drive/MyDrive/yolov8_custom.pt\n"
          ]
        }
      ],
      "source": [
        "# Cargar el modelo\n",
        "model_path = \"yolov8l.pt\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Ruta del archivo de datos (data.yaml) que contiene las rutas de las imágenes de entrenamiento y validación\n",
        "train_data = \"/content/drive/MyDrive/basketball/data.yaml\"\n",
        "\n",
        "# Ruta de guardado del modelo entrenado\n",
        "save_path = \"/content/drive/MyDrive/yolov8_custom.pt\"\n",
        "\n",
        "# Reentrenar el modelo\n",
        "retrain_model(model, train_data, save_path=save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluation on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se evaluó el modelo final (`best.pt`) obteniendo los siguientes resultados promedio:\n",
        "- **Precisión (P):** 0.865  \n",
        "- **Recall (R):** 0.840  \n",
        "- **mAP@0.5:** 0.902  \n",
        "- **mAP@0.5:0.95:** 0.649  \n",
        "\n",
        "**Precisión por clase:**\n",
        "- **Clase 0:** 0.865  \n",
        "- **Clase 1:** 0.878  \n",
        "- **Clase 3:** 0.966  \n",
        "\n",
        "Las métricas indican un buen rendimiento general en todas las clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results and discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo logró una alta precisión en la mayoría de las clases, especialmente en la clase 3 (0.966 de precisión y 0.914 de recall). También se observaron buenos resultados en la clase 1 (precisión de 0.878) y clase 0 (precisión de 0.865). Sin embargo, hay margen de mejora en clases con menor recall. Posibles siguientes pasos:\n",
        "- Entrenar más épocas\n",
        "- Mejorar la calidad de las etiquetas\n",
        "- Ajustar el esquema de augmentations"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
