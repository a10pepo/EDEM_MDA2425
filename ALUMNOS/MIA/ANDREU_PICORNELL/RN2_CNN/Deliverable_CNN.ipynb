{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detecci贸n de objetos en im谩genes con CNNs: Conteo de canastas de baloncesto  \n",
        "\n",
        "El objetivo principal de este proyecto es desarrollar un sistema de visi贸n por computadora capaz de detectar el bal贸n y el aro de baloncesto en un video, utilizando una red neuronal convolucional basada en la arquitectura YOLOv8. A partir de estas detecciones, el sistema implementa una l贸gica para contar autom谩ticamente la cantidad de canastas realizadas durante el transcurso del video. Esta aplicaci贸n puede ser 煤til en contextos deportivos para an谩lisis autom谩tico de jugadas o recopilaci贸n de estad铆sticas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset description, download and exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Nombre del conjunto de datos**: Basketball Detection (Versi贸n 1)\n",
        "- **Fuente**: Roboflow Universe  \n",
        "  - **URL**: [https://universe.roboflow.com/basketball-6vyfz/basketball-detection-srfkd](https://universe.roboflow.com/basketball-6vyfz/basketball-detection-srfkd)\n",
        "  - **Licencia**: CC BY 4.0\n",
        "\n",
        "- **Contenido**: El conjunto de datos contiene im谩genes de partidos de baloncesto anotadas con *bounding boxes* para distintos objetos clave en el juego.\n",
        "\n",
        "- **Clases de objetos**:\n",
        "  - `0`: Ball  \n",
        "  - `1`: Hoop with ball \n",
        "  - `2`: Player  \n",
        "  - `3`: Hoop  \n",
        "  - `4`: Player shooting  \n",
        "\n",
        "- **Formato de anotaci贸n**: YOLOv5/YOLOv8. Cada archivo `.txt` contiene una l铆nea por objeto detectado con el siguiente formato:\n",
        "`<class_id> <x_center> <y_center> <width> <height>`.\n",
        "\n",
        "- **Distribuci贸n del dataset**:\n",
        "  - **Entrenamiento**: 9,599 im谩genes (88%)\n",
        "  - **Validaci贸n**: 873 im谩genes (8%)\n",
        "  - **Pruebas**: 436 im谩genes (4%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data preparation and augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se aplicaron augmentations autom谩ticas provistas por YOLOv8, incluyendo:\n",
        "- Escalado aleatorio\n",
        "- Desenfoque (blur)\n",
        "- CLAHE (mejora de contraste)\n",
        "- Transformaci贸n a escala de grises\n",
        "\n",
        "Esto ayud贸 a mejorar la robustez del modelo y evitar el sobreajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se seleccion贸 el modelo `yolov8l.pt` (versi贸n large de YOLOv8) como punto de partida por su buen balance entre velocidad y precisi贸n. El modelo fue ajustado para detectar las 5 clases del dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo fue entrenado durante **10 茅pocas** con im谩genes de tama帽o **640x640**. Se utiliz贸 el optimizador **AdamW**, con validaci贸n autom谩tica despu茅s de cada 茅poca. El modelo mostr贸 mejoras constantes en precisi贸n y recall.\n",
        "\n",
        "- **C贸digo de entrenamiento utilizado**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uW0EQREsH-8"
      },
      "source": [
        "Instalar la librer铆a ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from google.colab import drive, files\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67GI0UP1s0Dk"
      },
      "source": [
        "Montar Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW1QhV5QsUCb",
        "outputId": "ea097fb4-94a7-4060-a6a8-2896460e2362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qELu7T2Zs49z"
      },
      "source": [
        "Cargar modelo YOLOv8l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2QEULwJsWpU"
      },
      "outputs": [],
      "source": [
        "# Cargar el modelo\n",
        "def load_model(model_path=\"yolov8l.pt\"):\n",
        "    model = YOLO(model_path)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUuqqexCs-AT"
      },
      "source": [
        "Entrenar el modelo con el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_IisodwtBPj"
      },
      "outputs": [],
      "source": [
        "# Funci贸n para reentrenar el modelo y guardarlo\n",
        "def retrain_model(model, train_data, epochs=10, batch=16, save_path=\"yolov8_custom.pt\"):\n",
        "    # Entrenar el modelo con los datos proporcionados\n",
        "    model.train(data=train_data, epochs=epochs, batch=batch)\n",
        "\n",
        "    # Guardar el modelo reentrenado\n",
        "    model.save(save_path)\n",
        "    print(f\"Modelo guardado en {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_zvAxBitIrs"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIc_WcLUsZ3j",
        "outputId": "4942db48-2eb7-4e9a-cca8-cfa79322e36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 83.7M/83.7M [00:00<00:00, 104MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.99  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=/content/drive/MyDrive/basketball/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 755k/755k [00:00<00:00, 21.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5586655  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,633,695 parameters, 43,633,679 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 5.35M/5.35M [00:00<00:00, 96.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/basketball/train/labels.cache... 9597 images, 0 backgrounds, 2 corrupt: 100%|| 9599/9599 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /content/drive/MyDrive/basketball/train/images/119_jpg.rf.9488c2eb7899362d87cd014c5dc8ca8a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /content/drive/MyDrive/basketball/train/images/119_jpg.rf.974639efdbc3b7e45ad151fb110b98e9.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /content/drive/MyDrive/basketball/train/images/119_jpg.rf.ef4dbb83db1d69dc7dc7f249865f94c4.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /content/drive/MyDrive/basketball/train/images/185_jpg.rf.36369d29da945e0cbb2e7f2253c06a9b.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /content/drive/MyDrive/basketball/train/images/185_jpg.rf.f653197f23d5cc7eda4e07982d00369f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /content/drive/MyDrive/basketball/train/images/185_jpg.rf.f7b2bca1e505d60739115fbcfa68a14d.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /content/drive/MyDrive/basketball/train/images/basketball_484_jpg.rf.eba3fa6a05657d4bf8074cf0d8c8486f.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/basketball/train/images/basketball_484_jpg.rf.eba3fa6a05657d4bf8074cf0d8c8486f.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /content/drive/MyDrive/basketball/train/images/basketball_4_jpg.rf.a8336a8ab5242dfcf3cf4708fd8417f4.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/basketball/train/images/basketball_4_jpg.rf.a8336a8ab5242dfcf3cf4708fd8417f4.jpg'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/basketball/valid/labels.cache... 873 images, 0 backgrounds, 0 corrupt: 100%|| 873/873 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/10      9.59G      1.426      1.541        1.5         45        640: 100%|| 600/600 [38:12<00:00,  3.82s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:18<00:00,  1.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.633       0.43      0.519      0.289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/10      11.1G      1.523      1.486      1.594         48        640: 100%|| 600/600 [07:42<00:00,  1.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:17<00:00,  1.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.635      0.479      0.555      0.317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/10      11.1G      1.433      1.337      1.522         48        640: 100%|| 600/600 [07:38<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:18<00:00,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.688      0.541      0.605      0.354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/10      11.1G      1.359      1.183      1.461         39        640: 100%|| 600/600 [07:37<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:17<00:00,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.766      0.662      0.746      0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/10      11.1G       1.28      1.061      1.411         49        640: 100%|| 600/600 [07:36<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:17<00:00,  1.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.803      0.705      0.779      0.498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/10      11.1G      1.217     0.9549      1.366         53        640: 100%|| 600/600 [07:36<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:17<00:00,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.792      0.733      0.809      0.537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/10      11.1G      1.161     0.8839      1.329         58        640: 100%|| 600/600 [07:37<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:18<00:00,  1.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.815       0.77      0.841       0.57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/10      11.2G      1.113     0.8004      1.288         60        640: 100%|| 600/600 [07:36<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:18<00:00,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.827        0.8      0.864      0.598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/10      11.2G      1.069     0.7405       1.26         38        640: 100%|| 600/600 [07:37<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:17<00:00,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.865      0.819      0.889      0.626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/10      11.2G      1.021      0.682      1.226         34        640: 100%|| 600/600 [07:37<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:17<00:00,  1.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.863       0.84      0.902      0.649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "10 epochs completed in 1.859 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.99  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 112 layers, 43,610,463 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 28/28 [00:20<00:00,  1.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        873       3408      0.865       0.84      0.902      0.649\n",
            "                     0        751        876      0.897      0.732      0.845      0.585\n",
            "                     1         78         78      0.837      0.858       0.91        0.7\n",
            "                     2        549       1690      0.878      0.875      0.923      0.637\n",
            "                     3        573        600      0.966      0.914      0.965      0.732\n",
            "                     4        164        164      0.745      0.823      0.865      0.593\n",
            "Speed: 0.3ms preprocess, 15.5ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Modelo guardado en /content/drive/MyDrive/yolov8_custom.pt\n"
          ]
        }
      ],
      "source": [
        "# Cargar el modelo\n",
        "model_path = \"yolov8l.pt\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Ruta del archivo de datos (data.yaml) que contiene las rutas de las im谩genes de entrenamiento y validaci贸n\n",
        "train_data = \"/content/drive/MyDrive/basketball/data.yaml\"\n",
        "\n",
        "# Ruta de guardado del modelo entrenado\n",
        "save_path = \"/content/drive/MyDrive/yolov8_custom.pt\"\n",
        "\n",
        "# Reentrenar el modelo\n",
        "retrain_model(model, train_data, save_path=save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluation on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se evalu贸 el modelo final (`best.pt`) obteniendo los siguientes resultados promedio:\n",
        "- **Precisi贸n (P):** 0.865  \n",
        "- **Recall (R):** 0.840  \n",
        "- **mAP@0.5:** 0.902  \n",
        "- **mAP@0.5:0.95:** 0.649  \n",
        "\n",
        "**Precisi贸n por clase:**\n",
        "- **Clase 0:** 0.865  \n",
        "- **Clase 1:** 0.878  \n",
        "- **Clase 3:** 0.966  \n",
        "\n",
        "Las m茅tricas indican un buen rendimiento general en todas las clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results and discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo logr贸 una alta precisi贸n en la mayor铆a de las clases, especialmente en la clase 3 (0.966 de precisi贸n y 0.914 de recall). Tambi茅n se observaron buenos resultados en la clase 1 (precisi贸n de 0.878) y clase 0 (precisi贸n de 0.865). Sin embargo, hay margen de mejora en clases con menor recall. Posibles siguientes pasos:\n",
        "- Entrenar m谩s 茅pocas\n",
        "- Mejorar la calidad de las etiquetas\n",
        "- Ajustar el esquema de augmentations"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
