{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines: Metaflow model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -p 8888:8888 quay.io/jupyter/scipy-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting metaflow==2.13.9\n",
      "  Downloading metaflow-2.13.9-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pandas==2.2.3 in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /opt/conda/lib/python3.12/site-packages (1.6.1)\n",
      "Collecting optuna==4.2.0\n",
      "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from metaflow==2.13.9) (2.32.3)\n",
      "Collecting boto3 (from metaflow==2.13.9)\n",
      "  Downloading boto3-1.37.16-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.3) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.6.1) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.6.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.6.1) (3.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from optuna==4.2.0) (1.14.1)\n",
      "Collecting colorlog (from optuna==4.2.0)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from optuna==4.2.0) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.12/site-packages (from optuna==4.2.0) (2.0.38)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from optuna==4.2.0) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.12/site-packages (from optuna==4.2.0) (6.0.2)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna==4.2.0) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna==4.2.0) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna==4.2.0) (3.1.1)\n",
      "Collecting botocore<1.38.0,>=1.37.16 (from boto3->metaflow==2.13.9)\n",
      "  Downloading botocore-1.37.16-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->metaflow==2.13.9)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->metaflow==2.13.9)\n",
      "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->metaflow==2.13.9) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->metaflow==2.13.9) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->metaflow==2.13.9) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->metaflow==2.13.9) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna==4.2.0) (3.0.2)\n",
      "Downloading metaflow-2.13.9-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
      "Downloading boto3-1.37.16-py3-none-any.whl (139 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading botocore-1.37.16-py3-none-any.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: numpy, jmespath, colorlog, botocore, s3transfer, optuna, boto3, metaflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed boto3-1.37.16 botocore-1.37.16 colorlog-6.9.0 jmespath-1.0.1 metaflow-2.13.9 numpy-1.26.4 optuna-4.2.0 s3transfer-0.11.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install metaflow==2.13.9 pandas==2.2.3 numpy==1.26.4 scikit-learn==1.6.1 optuna==4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set username for workflows\n",
    "import os\n",
    "os.environ[\"USERNAME\"] = \"pablo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting metaflow_trainingflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile metaflow_trainingflow.py\n",
    "from metaflow import FlowSpec, Parameter, step\n",
    "\n",
    "class TrainingFlow(FlowSpec):\n",
    "    # Define the parameters for the flow\n",
    "    max_depth = Parameter('max_depth', default=2, help='Max depth of the random forest classifier')\n",
    "    n_estimators = Parameter('n_estimators', default=100, help='Number of estimators for the random forest classifier')\n",
    "    random_state = Parameter('random_state', default=0, help='Random state for the random forest classifier')\n",
    "    \n",
    "    @step\n",
    "    def start(self):\n",
    "        # Start the flow\n",
    "        self.next(self.ingest_data)\n",
    "        \n",
    "    @step\n",
    "    def ingest_data(self):\n",
    "        from sklearn.datasets import load_iris\n",
    "    \n",
    "        # Load the iris dataset\n",
    "        iris = load_iris()\n",
    "        \n",
    "        #pylint: disable=no-member\n",
    "        self.X = iris.data\n",
    "        self.y = iris.target\n",
    "        #pylint: enable=no-member\n",
    "        \n",
    "        self.next(self.split_data)\n",
    "\n",
    "    @step\n",
    "    def split_data(self):\n",
    "        # Split the data into train and test\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=self.random_state)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.next(self.train)\n",
    "\n",
    "    @step\n",
    "    def train(self):\n",
    "        # Train the model\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        # Create the random forest classifier\n",
    "        self.rf = RandomForestClassifier(max_depth=self.max_depth, n_estimators=self.n_estimators, random_state=self.random_state)\n",
    "        # Train the model\n",
    "        self.rf.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self.next(self.show_metrics)\n",
    "\n",
    "    @step\n",
    "    def show_metrics(self):\n",
    "        # Print some metrics\n",
    "        from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "        \n",
    "        y_pred = self.rf.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        report = classification_report(self.y_test, y_pred)\n",
    "        confusion = confusion_matrix(self.y_test, y_pred)\n",
    "        \n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Report:\\n{report}')\n",
    "        print(f'Confusion matrix:\\n{confusion}')\n",
    "\n",
    "        self.next(self.register_model)\n",
    "        \n",
    "    @step\n",
    "    def register_model(self):\n",
    "        # Save the model in a pickle file in local storage\n",
    "        import pickle\n",
    "        with open('model.pkl', 'wb') as f:\n",
    "            pickle.dump(self.rf, f)\n",
    "        \n",
    "        self.next(self.end)\n",
    "        \n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    TrainingFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.13.9\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTrainingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:pablo\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    Pylint not found, so extra checks are disabled.\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:11.409 \u001b[0m\u001b[1mWorkflow starting (run-id 1742497151406177):\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:11.416 \u001b[0m\u001b[32m[1742497151406177/start/1 (pid 3712)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:11.622 \u001b[0m\u001b[32m[1742497151406177/start/1 (pid 3712)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:11.625 \u001b[0m\u001b[32m[1742497151406177/ingest_data/2 (pid 3714)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:12.693 \u001b[0m\u001b[32m[1742497151406177/ingest_data/2 (pid 3714)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:12.698 \u001b[0m\u001b[32m[1742497151406177/split_data/3 (pid 3771)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:13.698 \u001b[0m\u001b[32m[1742497151406177/split_data/3 (pid 3771)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:13.717 \u001b[0m\u001b[32m[1742497151406177/train/4 (pid 3836)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:14.887 \u001b[0m\u001b[32m[1742497151406177/train/4 (pid 3836)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:14.891 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:15.810 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22mAccuracy: 1.0\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.000 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22mReport:\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22mprecision    recall  f1-score   support\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22m0       1.00      1.00      1.00        11\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22m1       1.00      1.00      1.00        13\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22m2       1.00      1.00      1.00         6\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22maccuracy                           1.00        30\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22mmacro avg       1.00      1.00      1.00        30\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22mweighted avg       1.00      1.00      1.00        30\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22mConfusion matrix:\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22m[[11  0  0]\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22m[ 0 13  0]\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.001 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[22m[ 0  0  6]]\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.002 \u001b[0m\u001b[32m[1742497151406177/show_metrics/5 (pid 3893)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:16.006 \u001b[0m\u001b[32m[1742497151406177/register_model/6 (pid 3950)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:17.308 \u001b[0m\u001b[32m[1742497151406177/register_model/6 (pid 3950)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:17.313 \u001b[0m\u001b[32m[1742497151406177/end/7 (pid 4015)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:17.567 \u001b[0m\u001b[32m[1742497151406177/end/7 (pid 4015)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2025-03-20 18:59:17.568 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python metaflow_trainingflow.py run --max_depth 2 --n_estimators 100 --random_state 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ed29f95de7cc8ac0f18a32ccae5fbddd3dba9010e060d505f2ebe31fc64f080"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
