{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: opencv-python in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mauro/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow opencv-python numpy pandas scikit-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 401ms/step - accuracy: 0.1597 - loss: 1.5780 - val_accuracy: 0.0000e+00 - val_loss: 2.7498\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 378ms/step - accuracy: 0.2667 - loss: 1.5203 - val_accuracy: 0.0000e+00 - val_loss: 2.2504\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 367ms/step - accuracy: 0.3579 - loss: 1.3590 - val_accuracy: 0.0000e+00 - val_loss: 2.9884\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 375ms/step - accuracy: 0.2491 - loss: 1.3350 - val_accuracy: 0.0000e+00 - val_loss: 2.8369\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 372ms/step - accuracy: 0.2504 - loss: 1.3602 - val_accuracy: 0.0000e+00 - val_loss: 2.8374\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 382ms/step - accuracy: 0.2886 - loss: 1.4728 - val_accuracy: 0.0000e+00 - val_loss: 2.7042\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 392ms/step - accuracy: 0.0649 - loss: 1.2907 - val_accuracy: 0.0000e+00 - val_loss: 3.2316\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 398ms/step - accuracy: 0.3192 - loss: 1.4071 - val_accuracy: 0.0000e+00 - val_loss: 2.6673\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 415ms/step - accuracy: 0.2110 - loss: 1.3499 - val_accuracy: 0.0000e+00 - val_loss: 2.4949\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 411ms/step - accuracy: 0.4675 - loss: 1.2011 - val_accuracy: 0.0000e+00 - val_loss: 3.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 352ms/step - accuracy: 0.2708 - loss: 1.5195\n",
      "Accuracy en el conjunto de entrenamiento: 25.00%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Funci√≥n para extraer frames de un v√≠deo a intervalos dados por sample_rate\n",
    "def extract_frames(video_path, sample_rate=30, resize_dim=(160, 160)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames por segundo del v√≠deo\n",
    "    frames = []\n",
    "    \n",
    "    # Se toma un frame cada 'sample_rate' frames\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if count % sample_rate == 0:\n",
    "            frame = cv2.resize(frame, resize_dim)  # Redimensionar frame a 160x160\n",
    "            frames.append(frame)\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# Funci√≥n para cargar y preprocesar v√≠deos de un conjunto reducido (5 deportes)\n",
    "def load_videos_from_dataset(dataset_path, sample_rate=30, max_len=20, max_videos_per_class=10):\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    selected_classes = ['Yoyo', 'Basketball', 'Pushups', 'Nunchucks', 'Tennis']\n",
    "    \n",
    "    for class_idx, class_name in enumerate(selected_classes):\n",
    "        class_folder = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            videos = os.listdir(class_folder)[:max_videos_per_class]  # Limitar a 10 v√≠deos por clase\n",
    "            for video_name in videos:\n",
    "                video_path = os.path.join(class_folder, video_name)\n",
    "                video_paths.append(video_path)\n",
    "                labels.append(class_idx)\n",
    "    \n",
    "    X = []\n",
    "    for video_path in video_paths:\n",
    "        frames = extract_frames(video_path, sample_rate)\n",
    "        if len(frames) > max_len:\n",
    "            frames = frames[:max_len]\n",
    "        else:\n",
    "            frames = np.pad(frames, ((0, max_len - len(frames)), (0, 0), (0, 0), (0, 0)), 'constant')\n",
    "        X.append(frames)\n",
    "    \n",
    "    return np.array(X), np.array(labels)\n",
    "\n",
    "# Construcci√≥n de la CNN (Red Neuronal Convolucional)\n",
    "def build_cnn(input_shape=(160, 160, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5)  # A√±adir Dropout para regularizaci√≥n\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Modelo CNN + LSTM\n",
    "def build_model(input_shape=(20, 160, 160, 3), num_classes=5):\n",
    "    cnn_model = build_cnn(input_shape[1:])\n",
    "    model = models.Sequential([\n",
    "        layers.TimeDistributed(cnn_model, input_shape=input_shape),\n",
    "        layers.LSTM(128, return_sequences=False),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),  # Dropout adicional\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Cargar el dataset reducido con 5 deportes (Yoyo, Basketball, Pushups, Nunchucks, Tennis)\n",
    "dataset_path = '/Users/mauro/Documents/MIA/EDEM_MDA2425/ALUMNOS/MIA/MAURO_BALAGUER/RN3_RNN/UCF50'  # Aseg√∫rate de que este path sea correcto\n",
    "X_train, Y_train = load_videos_from_dataset(dataset_path, sample_rate=30, max_len=20, max_videos_per_class=10)\n",
    "\n",
    "# Convertir las etiquetas a formato one-hot\n",
    "Y_train_one_hot = to_categorical(Y_train, num_classes=5)\n",
    "\n",
    "# Aseguramos que las secuencias de entrada tengan la forma correcta\n",
    "X_train_padded = np.array(X_train)\n",
    "\n",
    "# Construir el modelo CNN + LSTM\n",
    "model = build_model()  # Usamos la funci√≥n build_model definida previamente\n",
    "\n",
    "# Entrenamiento del modelo utilizando fit() que tiene soporte nativo para barras de progreso\n",
    "model.fit(X_train_padded, Y_train_one_hot, epochs=10, batch_size=2, validation_split=0.2)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save('sports_classifier_5_sports.h5')\n",
    "\n",
    "# Evaluaci√≥n final en el conjunto de entrenamiento\n",
    "loss, accuracy = model.evaluate(X_train_padded, Y_train_one_hot)\n",
    "print(f\"Accuracy en el conjunto de entrenamiento: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo **CNN + LSTM** implementado logra un **25% de accuracy en entrenamiento**, lo cual indica un rendimiento bajo y cercano al azar (20% en un problema de 5 clases). Esto se debe principalmente a:\n",
    "\n",
    "- Pocos datos: solo 10 v√≠deos por clase no son suficientes para entrenar un modelo profundo.\n",
    "- Modelo demasiado complejo para el tama√±o del dataset.\n",
    "- Sampling limitado (1 frame cada 30), que puede omitir informaci√≥n relevante.\n",
    "\n",
    "**üîß Posibles mejoras:**\n",
    "\n",
    "- Aumentar el n√∫mero de v√≠deos y variedad de datos.\n",
    "- Usar una CNN preentrenada para extraer mejores caracter√≠sticas.\n",
    "- Capturar m√°s frames por v√≠deo.\n",
    "- Entrenar con m√°s **potencia computacional (GPUs)** para probar modelos m√°s avanzados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
