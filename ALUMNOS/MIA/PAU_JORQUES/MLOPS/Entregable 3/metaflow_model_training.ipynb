{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMyuIoICreTn"
      },
      "source": [
        "# Pipelines: Metaflow model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghl9k5lPreTo"
      },
      "source": [
        "##  Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiZZors8reTp",
        "outputId": "dd6c1e1d-8026-42dd-bee5-5d779d370c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: metaflow==2.13.9 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.13.9)\n",
            "Requirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.3)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: optuna==4.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from metaflow==2.13.9->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from metaflow==2.13.9->-r requirements.txt (line 1)) (1.37.33)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1->-r requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1->-r requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna==4.2.0->-r requirements.txt (line 5)) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna==4.2.0->-r requirements.txt (line 5)) (4.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna==4.2.0->-r requirements.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.33 in /usr/local/lib/python3.11/dist-packages (from boto3->metaflow==2.13.9->-r requirements.txt (line 1)) (1.37.33)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->metaflow==2.13.9->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->metaflow==2.13.9->-r requirements.txt (line 1)) (0.11.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9->-r requirements.txt (line 1)) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xmr0quJreTq"
      },
      "source": [
        "## Set username"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qdX3FgBsreTq"
      },
      "outputs": [],
      "source": [
        "# Set username for workflows\n",
        "import os\n",
        "os.environ[\"USERNAME\"] = \"pau\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A5WXVVureTq",
        "outputId": "ea659111-07bb-44a3-e303-e44bf0d61b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting metaflow_trainingflow.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile metaflow_trainingflow.py\n",
        "from metaflow import FlowSpec, Parameter, step\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "class TrainingFlow(FlowSpec):\n",
        "    # Define the parameters for the flow\n",
        "    max_depth = Parameter('max_depth', default=2, help='Max depth of the random forest classifier')\n",
        "    n_estimators = Parameter('n_estimators', default=100, help='Number of estimators for the random forest classifier')\n",
        "    random_state = Parameter('random_state', default=0, help='Random state for the random forest classifier')\n",
        "\n",
        "    @step\n",
        "    def start(self):\n",
        "        # Start the flow\n",
        "        self.next(self.ingest_data)\n",
        "\n",
        "    @step\n",
        "    def ingest_data(self):\n",
        "        from sklearn.datasets import load_iris\n",
        "\n",
        "        # Load the iris dataset\n",
        "        iris = load_iris()\n",
        "\n",
        "        #pylint: disable=no-member\n",
        "        self.X = iris.data\n",
        "        self.y = iris.target\n",
        "        #pylint: enable=no-member\n",
        "\n",
        "        self.next(self.split_data)\n",
        "\n",
        "    @step\n",
        "    def split_data(self):\n",
        "        #Split the data into train and test\n",
        "        # TODO: WRITE YOUR CODE HERE\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.8, random_state=self.random_state)\n",
        "        self.next(self.train)\n",
        "\n",
        "    @step\n",
        "    def train(self):\n",
        "        # Train the model\n",
        "        # TODO: WRITE YOUR CODE HERE\n",
        "        self.rfc = RandomForestClassifier(max_depth=self.max_depth, n_estimators=self.n_estimators, random_state=self.random_state)\n",
        "        self.rfc.fit(self.X_train, self.y_train)\n",
        "        self.next(self.show_metrics)\n",
        "\n",
        "\n",
        "    @step\n",
        "    def show_metrics(self):\n",
        "        # Print some metrics\n",
        "        # TODO: WRITE YOUR CODE HERE\n",
        "        y_pred = self.rfc.predict(self.X_test)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_test, y_pred)\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "        conf_matrix = confusion_matrix(self.y_test, y_pred)\n",
        "        print(\"Confussion Matrix: \")\n",
        "        print(conf_matrix)\n",
        "\n",
        "        self.next(self.register_model)\n",
        "\n",
        "\n",
        "\n",
        "    @step\n",
        "    def register_model(self):\n",
        "        # Save the model in a pickle file in local storage\n",
        "        # TODO: WRITE YOUR CODE HERE\n",
        "        model_path = os.path.join(\"model\", \"model.pkl\")\n",
        "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "        with open(model_path, 'wb') as f:\n",
        "          pickle.dump(self.rfc, f)\n",
        "\n",
        "        self.next(self.end)\n",
        "\n",
        "    @step\n",
        "    def end(self):\n",
        "        print(\"Flow finished\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    TrainingFlow()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-u6Ewn3reTr",
        "outputId": "d0589aa9-4758-46ea-f1e6-483517cbdfee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[35m\u001b[1mMetaflow 2.13.9\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTrainingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:pau\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
            "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[32m\u001b[22m    Pylint not found, so extra checks are disabled.\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
            "\u001b[35m2025-04-12 16:04:57.203 \u001b[0m\u001b[1mWorkflow starting (run-id 1744473897201488):\u001b[0m\n",
            "\u001b[35m2025-04-12 16:04:57.294 \u001b[0m\u001b[32m[1744473897201488/start/1 (pid 5784)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:03.724 \u001b[0m\u001b[32m[1744473897201488/start/1 (pid 5784)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:03.745 \u001b[0m\u001b[32m[1744473897201488/ingest_data/2 (pid 5819)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:08.995 \u001b[0m\u001b[32m[1744473897201488/ingest_data/2 (pid 5819)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:09.002 \u001b[0m\u001b[32m[1744473897201488/split_data/3 (pid 5846)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:16.435 \u001b[0m\u001b[32m[1744473897201488/split_data/3 (pid 5846)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:16.450 \u001b[0m\u001b[32m[1744473897201488/train/4 (pid 5881)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:21.258 \u001b[0m\u001b[32m[1744473897201488/train/4 (pid 5881)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:21.264 \u001b[0m\u001b[32m[1744473897201488/show_metrics/5 (pid 5908)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:23.112 \u001b[0m\u001b[32m[1744473897201488/show_metrics/5 (pid 5908)] \u001b[0m\u001b[22mAccuracy: 0.92\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:23.113 \u001b[0m\u001b[32m[1744473897201488/show_metrics/5 (pid 5908)] \u001b[0m\u001b[22mConfussion Matrix:\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:23.114 \u001b[0m\u001b[32m[1744473897201488/show_metrics/5 (pid 5908)] \u001b[0m\u001b[22m[[40  0  0]\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:23.610 \u001b[0m\u001b[32m[1744473897201488/show_metrics/5 (pid 5908)] \u001b[0m\u001b[22m[ 0 39  0]\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:23.611 \u001b[0m\u001b[32m[1744473897201488/show_metrics/5 (pid 5908)] \u001b[0m\u001b[22m[ 0 10 31]]\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:23.612 \u001b[0m\u001b[32m[1744473897201488/show_metrics/5 (pid 5908)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:23.618 \u001b[0m\u001b[32m[1744473897201488/register_model/6 (pid 5923)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:26.824 \u001b[0m\u001b[32m[1744473897201488/register_model/6 (pid 5923)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:26.831 \u001b[0m\u001b[32m[1744473897201488/end/7 (pid 5946)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:28.571 \u001b[0m\u001b[32m[1744473897201488/end/7 (pid 5946)] \u001b[0m\u001b[22mFlow finished\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:28.909 \u001b[0m\u001b[32m[1744473897201488/end/7 (pid 5946)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-12 16:05:28.910 \u001b[0m\u001b[1mDone!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python metaflow_trainingflow.py run --max_depth 2 --n_estimators 100 --random_state 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NqBecR6OwP41"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "productionalization",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "5ed29f95de7cc8ac0f18a32ccae5fbddd3dba9010e060d505f2ebe31fc64f080"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}