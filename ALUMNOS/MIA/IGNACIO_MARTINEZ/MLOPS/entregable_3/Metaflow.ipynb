{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install metaflow==2.13.9 pandas==2.2.3 numpy==1.26.4 scikit-learn==1.6.1 optuna==4.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRmkIxMMp7IM",
        "outputId": "c4c4ace9-2dfd-469d-ad27-3dd4bcd3a900"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: metaflow==2.13.9 in /usr/local/lib/python3.11/dist-packages (2.13.9)\n",
            "Requirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: optuna==4.2.0 in /usr/local/lib/python3.11/dist-packages (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from metaflow==2.13.9) (2.32.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from metaflow==2.13.9) (1.37.24)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (3.6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.0) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna==4.2.0) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna==4.2.0) (4.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna==4.2.0) (3.1.1)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.24 in /usr/local/lib/python3.11/dist-packages (from boto3->metaflow==2.13.9) (1.37.24)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->metaflow==2.13.9) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->metaflow==2.13.9) (0.11.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->metaflow==2.13.9) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set username for workflows\n",
        "import os\n",
        "os.environ[\"USERNAME\"] = \"nacho\""
      ],
      "metadata": {
        "id": "V6WXnAZcrdSg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-bh3JO5pyzw",
        "outputId": "51e561db-2e57-4597-d5e9-a1f484498529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing metaflow_trainingflow.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile metaflow_trainingflow.py\n",
        "from metaflow import FlowSpec, Parameter, step\n",
        "\n",
        "class TrainingFlow(FlowSpec):\n",
        "    # Define the parameters for the flow\n",
        "    max_depth = Parameter('max_depth', default=2, help='Max depth of the random forest classifier')\n",
        "    n_estimators = Parameter('n_estimators', default=100, help='Number of estimators for the random forest classifier')\n",
        "    random_state = Parameter('random_state', default=0, help='Random state for the random forest classifier')\n",
        "\n",
        "    @step\n",
        "    def start(self):\n",
        "        # Start the flow\n",
        "        self.next(self.ingest_data)\n",
        "\n",
        "    @step\n",
        "    def ingest_data(self):\n",
        "        from sklearn.datasets import load_iris\n",
        "\n",
        "        # Load the iris dataset\n",
        "        iris = load_iris()\n",
        "\n",
        "        #pylint: disable=no-member\n",
        "        self.X = iris.data\n",
        "        self.y = iris.target\n",
        "        #pylint: enable=no-member\n",
        "\n",
        "        self.next(self.split_data)\n",
        "\n",
        "    @step\n",
        "    def split_data(self):\n",
        "        # Split the data into train and test\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=self.random_state)\n",
        "\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "\n",
        "        self.next(self.train)\n",
        "\n",
        "    @step\n",
        "    def train(self):\n",
        "        # Train the model\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "        # Create the random forest classifier\n",
        "        self.rf = RandomForestClassifier(max_depth=self.max_depth, n_estimators=self.n_estimators, random_state=self.random_state)\n",
        "        # Train the model\n",
        "        self.rf.fit(self.X_train, self.y_train)\n",
        "\n",
        "        self.next(self.show_metrics)\n",
        "\n",
        "    @step\n",
        "    def show_metrics(self):\n",
        "        # Print some metrics\n",
        "        from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "        y_pred = self.rf.predict(self.X_test)\n",
        "        accuracy = accuracy_score(self.y_test, y_pred)\n",
        "        report = classification_report(self.y_test, y_pred)\n",
        "        confusion = confusion_matrix(self.y_test, y_pred)\n",
        "\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print(f'Report:\\n{report}')\n",
        "        print(f'Confusion matrix:\\n{confusion}')\n",
        "\n",
        "        self.next(self.register_model)\n",
        "\n",
        "    @step\n",
        "    def register_model(self):\n",
        "        # Save the model in a pickle file in local storage\n",
        "        import pickle\n",
        "        with open('model.pkl', 'wb') as f:\n",
        "            pickle.dump(self.rf, f)\n",
        "\n",
        "        self.next(self.end)\n",
        "\n",
        "    @step\n",
        "    def end(self):\n",
        "        pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    TrainingFlow()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python metaflow_trainingflow.py run --max_depth 2 --n_estimators 100 --random_state 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8dIrV2Orom7",
        "outputId": "10ddf3bf-0e33-4402-87bc-292afd07e58b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[35m\u001b[1mMetaflow 2.13.9\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTrainingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:nacho\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[22mCreating local datastore in current directory (/content/.metaflow)\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
            "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
            "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[32m\u001b[22m    Pylint not found, so extra checks are disabled.\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:42.895 \u001b[0m\u001b[1mWorkflow starting (run-id 1743516522893715):\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:42.913 \u001b[0m\u001b[32m[1743516522893715/start/1 (pid 3207)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:43.932 \u001b[0m\u001b[32m[1743516522893715/start/1 (pid 3207)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:43.941 \u001b[0m\u001b[32m[1743516522893715/ingest_data/2 (pid 3213)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:46.983 \u001b[0m\u001b[32m[1743516522893715/ingest_data/2 (pid 3213)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:46.987 \u001b[0m\u001b[32m[1743516522893715/split_data/3 (pid 3233)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:48.702 \u001b[0m\u001b[32m[1743516522893715/split_data/3 (pid 3233)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:48.705 \u001b[0m\u001b[32m[1743516522893715/train/4 (pid 3248)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:51.523 \u001b[0m\u001b[32m[1743516522893715/train/4 (pid 3248)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:51.526 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.072 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22mAccuracy: 1.0\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.072 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22mReport:\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22mprecision    recall  f1-score   support\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22m\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22m0       1.00      1.00      1.00        11\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22m1       1.00      1.00      1.00        13\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22m2       1.00      1.00      1.00         6\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22m\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22maccuracy                           1.00        30\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22mmacro avg       1.00      1.00      1.00        30\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22mweighted avg       1.00      1.00      1.00        30\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22m\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.073 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22mConfusion matrix:\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.396 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22m[[11  0  0]\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.396 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22m[ 0 13  0]\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.396 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[22m[ 0  0  6]]\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.397 \u001b[0m\u001b[32m[1743516522893715/show_metrics/5 (pid 3267)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:53.401 \u001b[0m\u001b[32m[1743516522893715/register_model/6 (pid 3282)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:55.233 \u001b[0m\u001b[32m[1743516522893715/register_model/6 (pid 3282)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:55.237 \u001b[0m\u001b[32m[1743516522893715/end/7 (pid 3293)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:55.658 \u001b[0m\u001b[32m[1743516522893715/end/7 (pid 3293)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2025-04-01 14:08:55.659 \u001b[0m\u001b[1mDone!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0EWpP4-mrtbG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}