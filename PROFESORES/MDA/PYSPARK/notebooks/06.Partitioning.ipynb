{"cells":[{"cell_type":"markdown","metadata":{"id":"BNkZfzfxGZ0z"},"source":["# Partitioning"]},{"cell_type":"markdown","metadata":{"id":"AQieQ5pkGfNm"},"source":["## Prerrequisites"]},{"cell_type":"markdown","metadata":{"id":"HelxRmCPGpql"},"source":["Install Spark and Java in VM"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":57405,"status":"ok","timestamp":1670666888439,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"9Cn3c-ywGtDV"},"outputs":[],"source":["# install Java8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# download spark 3.5.0\n","!wget -q https://apache.osuosl.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1670666888440,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"D95sNcJfGvyV","outputId":"7b823201-ab1c-4452-d091-bb995fd23e6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 267680\n","drwxr-xr-x 1 root root      4096 Dec  8 14:36 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n","-rw-r--r-- 1 root root 274099817 Oct 15 10:53 spark-3.3.1-bin-hadoop2.tgz\n"]}],"source":["ls -l # check the .tgz is there"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2865,"status":"ok","timestamp":1670666891295,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"qtBMGi7EGvwN"},"outputs":[],"source":["# unzip it\n","!tar xf spark-3.5.0-bin-hadoop3.tgz"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4334,"status":"ok","timestamp":1670666895619,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"6JO331NrGvtt"},"outputs":[],"source":["!pip install -q findspark"]},{"cell_type":"markdown","metadata":{"id":"02epIDkbG24d"},"source":["Defining the environment"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1670666895620,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"qmON5zHJG4-m"},"outputs":[],"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n","os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""]},{"cell_type":"markdown","metadata":{"id":"WgvNJQOAGZ00"},"source":["Start Spark Session\n","\n","---"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":6346,"status":"ok","timestamp":1670666901951,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"siaPZq4XGZ00","outputId":"517fa3d4-7f52-4b7b-f33a-b27ecef9a830"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'3.3.1'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import findspark\n","findspark.init(\"spark-3.5.0-bin-hadoop3\")# SPARK_HOME\n","\n","from pyspark.sql import SparkSession\n","\n","# create the session\n","spark = SparkSession \\\n","        .builder \\\n","        .appName(\"Window Partitioning Exercises\") \\\n","        .master(\"local[*]\") \\\n","        .getOrCreate()\n","\n","spark.version"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"elapsed":2348,"status":"ok","timestamp":1670666904291,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"nsBkpLh6GZ01","outputId":"8b85e798-6e00-4c6f-c200-9f257dec4f76"},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://771c95d68c87:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Window Partitioning Exercises</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f67255ec970>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1670666904291,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"Bqu4fQnNGZ02"},"outputs":[],"source":["# For Pandas conversion optimization\n","spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1670666904292,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"-9DDmYQKGZ02"},"outputs":[],"source":["# Import sql functions\n","from pyspark.sql.functions import *"]},{"cell_type":"markdown","metadata":{"id":"NYrtXWZIHKMt"},"source":["Download datasets"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2526,"status":"ok","timestamp":1670666906811,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"2lkKBm3CHL-l","outputId":"df5bac53-e576-4134-8560-d1fe2b81e002"},"outputs":[{"name":"stdout","output_type":"stream","text":["bank.csv  characters.csv  planets.csv  species.csv  vehicles.csv\n"]}],"source":["!mkdir -p /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/bank.csv -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/vehicles.csv -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/characters.csv -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/planets.csv -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/species.csv -P /dataset\n","!ls /dataset"]},{"cell_type":"markdown","metadata":{"id":"d1tEe9JCILAe"},"source":["## Examples"]},{"cell_type":"markdown","metadata":{"id":"HWlZ5puMLqvX"},"source":["### Patitioning"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":8328,"status":"ok","timestamp":1670666915136,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"B10rScPeIOCn"},"outputs":[],"source":["# Load characters CSV\n","charactersDF = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"/dataset/characters.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1489,"status":"ok","timestamp":1670666916608,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"_z47cLpVJQgV","outputId":"3df2be0d-f74d-4118-8b7a-e82fc900c949"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------+-----+\n","|partitionId|count|\n","+-----------+-----+\n","|          0|   87|\n","+-----------+-----+\n","\n"]}],"source":["# Show how the data is partitioned now\n","charactersDF \\\n","  .withColumn(\"partitionId\", spark_partition_id()) \\\n","  .groupBy(\"partitionId\") \\\n","  .count() \\\n","  .orderBy(col(\"count\").desc()) \\\n","  .show()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1525,"status":"ok","timestamp":1670666918132,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"NGfdi2WhJQeH","outputId":"4c872e9c-45ef-47e1-c092-87cd3e206764"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------+-----+\n","|partitionId|count|\n","+-----------+-----+\n","|          0|    4|\n","|          1|    4|\n","|          2|    4|\n","|          3|    4|\n","|          4|    4|\n","|          5|    4|\n","|          6|    4|\n","|          7|    4|\n","|          8|    4|\n","|          9|    5|\n","|         10|    5|\n","|         11|    5|\n","|         12|    5|\n","|         13|    5|\n","|         14|    5|\n","|         15|    5|\n","|         16|    4|\n","|         17|    4|\n","|         18|    4|\n","|         19|    4|\n","+-----------+-----+\n","\n"]}],"source":["# We will now repartition the DF to 20 partitions\n","charactersRepDF = charactersDF.repartition(20)\n","charactersRepDF \\\n","  .withColumn(\"partitionId\", spark_partition_id()) \\\n","  .groupBy(\"partitionId\") \\\n","  .count() \\\n","  .orderBy(col(\"partitionId\")) \\\n","  .show()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":706,"status":"ok","timestamp":1670666918833,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"sEwePVEfJvMN","outputId":"ab472f88-1eb1-4d87-bdcc-f4cbf77268f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------+-----+\n","|partitionId|count|\n","+-----------+-----+\n","|          0|   17|\n","|          1|   18|\n","|          2|   18|\n","|          3|   17|\n","|          4|   17|\n","+-----------+-----+\n","\n"]}],"source":["# Now we can use coalesce to reduce the number of partitions\n","charactersRepDF \\\n","  .coalesce(5) \\\n","  .withColumn(\"partitionId\", spark_partition_id()) \\\n","  .groupBy(\"partitionId\") \\\n","  .count() \\\n","  .orderBy(col(\"partitionId\")) \\\n","  .show()"]},{"cell_type":"markdown","metadata":{"id":"sxWVtHu5GZ02"},"source":["## Partitioning Exercises"]},{"cell_type":"markdown","metadata":{"id":"rZt5nAVLRmeF"},"source":["1. Try repartition/colaesce yourself"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DF-WHVfjRq49"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ff1af5cda0bea4fe5c4ebc1f94ab9f13d8998f98d08e16d8aba48673b9d00116"}}},"nbformat":4,"nbformat_minor":0}
